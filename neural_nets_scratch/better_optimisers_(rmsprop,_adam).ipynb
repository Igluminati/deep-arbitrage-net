{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146de2ad",
   "metadata": {},
   "source": [
    "[[Neural Networks from Scratch]]\n",
    "\n",
    "##### Why Move Beyond SGD?\n",
    "SGD performs blind updates meaning that it uses the same learning rate for all parameters and has no memory of past gradients. This is insufficient for high-dimensional, sparse, noisy, or dynamically shifting problems.\n",
    "\n",
    "### **RMSProp** - Root Mean Square Propagation\n",
    "##### The Core Idea Behind RMSProp\n",
    "`RMSProp` tracks an exponentially decaying of past squared gradients for each parameter, slowing updates for frequently changing parameters and speeding up for stable ones.\n",
    "$$\n",
    "g_t = \\beta g_{t-1} + (1-\\beta) \\nabla L^2\n",
    "$$\n",
    "$$\n",
    "\\theta = \\theta - \\frac{\\eta}{\\sqrt{g_t+\\epsilon}}*\\nabla L\n",
    "$$\n",
    "where:\n",
    "- $\\beta$ = 0.9: decay rate (this is called `rho` in the code)\n",
    "- $\\epsilon$ = 1e-7: prevents divide-by-zero\n",
    "- Adaptivity is **per-parameter**\n",
    "\n",
    "##### Implementation of `Optimiser_RMSprop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimiser_RMSprop:\n",
    "\tdef __init__(self, learning_rate=0.001, decay=0.0, epsilon=1e-7, rho=0.9):\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.current_learning_rate = learning_rate\n",
    "\t\tself.decay = decay\n",
    "\t\tself.iteration = 0\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.rho = rho\n",
    "\n",
    "\tdef pre_update_params(self):\n",
    "\t\tif self.decay:\n",
    "\t\t\tself.current_learning_rate = self.learning_rate * \\ (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "\tdef update_params(self, layer):\n",
    "\t\t# if the layer object does not yet have an attribute called `weight_cache`\n",
    "\t\tif not hasattr(layer, 'weight_cache'):\n",
    "\t\t\tlayer.weight_cache = np.zeros_like(layer.weights)\n",
    "\t\t\tlayer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "\t\tlayer.weight_momentums = self.rho * layer.weight_cache + \\ (1 - self.rho) * layer.dweights**2\n",
    "\t\tlayer.bias_cache = self.rho * layer.bias_cache + \\ (1 - self.rho) * layer.dbiases**2\n",
    "\n",
    "\t\tlayer.weights += -self.current_learning_rate * \\ layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "\t\tlayer.biases += -self.current_learning_rate * \\ layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "\tdef post_update_params(self):\n",
    "\t\tself.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778fb471",
   "metadata": {},
   "source": [
    "\n",
    "### **Adam** - Adaptive Moment Estimation\n",
    "##### The Core Idea Behind Adam\n",
    "Adam combines the **Momentum** - which is the average of past gradients - with **RMSProp** - which is the average of past squared gradients.\n",
    "\n",
    "With bias correction to stabilise early updates:\n",
    "$$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1)\\nabla L\n",
    "$$\n",
    "$$\n",
    "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2)(\\nabla L)^2\n",
    "$$\n",
    "$$\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "$$\n",
    "$$\n",
    "\\theta = \\theta - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "$$\n",
    "\n",
    "##### Implementation of `Optimiser Adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimiser_Adam:\n",
    "\tdef __init__(self, learning_rate=0.001, decay=0.0, epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.current_learning_rate = learning_rate\n",
    "\t\tself.decay = decay\n",
    "\t\tself.iterations = 0\n",
    "\t\tself.epsilon = epsilon # for numerical stability\n",
    "\t\tself.beta_1 = beta_1 # decay rate for first moment\n",
    "\t\tself.beta_2 = beta_2 # decay rate for second moment\n",
    "\n",
    "\tdef pre_update_params(self):\n",
    "\t\t# Decay learning rate if applicable\n",
    "\t\tif self.decay:\n",
    "\t\t\tself.current_learning_rate = self.learning_rate * \\\n",
    "\t\t\t\t(1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "\tdef update_params(self, layer):\n",
    "\t\t# if the layer object does not yet have an attribute called `weight_cache`\n",
    "\t\tif not hasattr(layer, 'weight_cache'):\n",
    "\t\t\tlayer.weight_momentums = np.zeros_like(layer.weights)\n",
    "\t\t\tlayer.weight_cache = np.zeros_like(layer.weights)\n",
    "\t\t\tlayer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\t\t\tlayer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "\t\t# update biased first moment estimate (momentum)\n",
    "\t\tlayer.weight_momentums = self.beta_1 * layer.weight_momentums + \\\n",
    "\t\t\t\t\t\t\t\t (1 - self.beta_1) * layer.dweights\n",
    "\t\tlayer.bias_momentums = self.beta_1 * layer.bias_momentums + \\\n",
    "\t\t\t\t\t\t\t\t(1 - self.beta_1) * layer.dbiases\n",
    "\n",
    "\t\t# correct bias in first moment\n",
    "\t\tcorrected_weight_momentums = layer.weight_momentums / \\\n",
    "\t\t\t\t\t\t\t\t\t (1 - self.beta_1 ** (self.iterations + 1))\n",
    "\t\tcorrected_bias_momentums = layer.bias_momentums / \\\n",
    "\t\t\t\t\t\t\t\t   (1 - self.beta_1 ** (self.iterations + 1))\n",
    "\n",
    "\t\t# update biased second moment estimate (squared gradient cache)\n",
    "\t\tlayer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
    "\t\t\t\t\t\t\t (1 - self.beta_2) * layer.dweights**2\n",
    "\t\tlayer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
    "\t\t\t\t\t\t   (1 - self.beta_2) * layer.dbiases**2\n",
    "\n",
    "\t\t# correct bias in second moment\n",
    "\t\tcorrected_weight_cache = layer.weight_cache / \\\n",
    "\t\t\t\t\t\t\t\t (1 - self.beta_2 ** (self.iterations + 1))\n",
    "\t\tcorrected_bias_cache = layer.bias_cache / \\\n",
    "\t\t\t\t\t\t\t   (1 - self.beta_2 ** (self.iterations + 1))\n",
    "\n",
    "\t\t# update weights and biases using Adam Formula\n",
    "\t\tlayer.weights += -self.current_learning_rate * corrected_weight_momentums / \\\n",
    "\t\t\t\t\t\t (np.sqrt(corrected_weight_cache) + self.epsilon)\n",
    "\t\tlayer.biases += -self.current_learning_rate * corrected_bias_momentums / \\\n",
    "\t\t\t\t\t\t(np.sqrt(corrected_bias_cache) + self.epsilon)\n",
    "\n",
    "\tdef post_update_params(self):\n",
    "\t\t# increment iteration count\n",
    "\t\tself.iterations += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da249ed",
   "metadata": {},
   "source": [
    "\n",
    "##### Usage Example\n",
    "Swap this line in the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9174470",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = Optimiser_Adam(learning_rate=0.02, decay=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e5d7e",
   "metadata": {},
   "source": [
    "\n",
    "##### Next Step:\n",
    "[[Batch Training]]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
