{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7d311f",
   "metadata": {},
   "source": [
    "[[Neural Networks from Scratch]]\n",
    "\n",
    "With our model up to this point, we've validated during training, but currently have no great way to run a test on data or perform a prediction. Initially we add a new `evaluate` method to the `Model` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the model using passed in dataset\n",
    "def evaluate(self, X_val, y_val, *, batch_size=None):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2f64e",
   "metadata": {},
   "source": [
    "The method above takes in samples (`X_val`), target outputs (`y_val`), and an optional batch size. First, we calculate the number of steps given the length of the data and the `batch_size` argument.\n",
    "\n",
    "This is the same as in the `train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value if batch size is not being set\n",
    "validation_steps = 1 \n",
    "\n",
    "# Calculate number of steps \n",
    "if batch_size is not None:\n",
    "\tvalidation_steps = len(X_val) // batch_size\n",
    "\t# Dividing rounds down. If there are some remaining\n",
    "\t# data, but not a full batch, this won't include it\n",
    "\t# Add `1` to include this not full batch\n",
    "\tif validation_steps * batch_size < len(X_val):\n",
    "\t\tvalidation_steps += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ca7ff",
   "metadata": {},
   "source": [
    "\n",
    "Then, we want to move a chunk of code from the `Model` class' `train` method:\n",
    "\n",
    "\n",
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y, X_test, y_test = create_data_mnist('fashion_mnist_images')\n",
    "\n",
    "# Shuffle the training dataset \n",
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys] \n",
    "\n",
    "# Scale and reshape samples\n",
    "X = (X.reshape(X.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
    "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# Instantiate the model\n",
    "model = Model()\n",
    "\n",
    "# Add layers\n",
    "model.add(Layer_Dense(X.shape[1], 128))\n",
    "model.add(Activation_ReLU()) model.add(Layer_Dense(128, 128))\n",
    "model.add(Activation_ReLU()) model.add(Layer_Dense(128, 10))\n",
    "model.add(Activation_Softmax())\n",
    "\n",
    "# Set loss, optimizer and accuracy objects\n",
    "model.set(\n",
    "\t\tLoss=Loss_CategoricalCrossentropy(),\n",
    "\t\toptimiser=Optimiser_Adam(decay=1e-3),\n",
    "\t\taccuracy=Accuracy_Categorical()\n",
    ")\n",
    "\t\t\n",
    "# Finalise the model\n",
    "model.finalise()\n",
    "\n",
    "# Train the model\n",
    "model.train(X, y, validation_data=(X_test, y_test), epochs=10, batch_size=128, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8955e",
   "metadata": {},
   "source": [
    "\n",
    "##### Testing the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72207d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6da89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f13cf8a6",
   "metadata": {},
   "source": [
    "Running this, we get:\n",
    ">>>\n",
    "...\n",
    "epoch: 10\n",
    "step: 0, acc: 0.891, loss: 0.263 (data_loss: 0.263, reg_loss: 0.000), lr: 0.0001915341888527102\n",
    "step: 100, acc: 0.883, loss: 0.257 (data_loss: 0.257, reg_loss: 0.000), lr: 0.00018793459875963167\n",
    "step: 200, acc: 0.922, loss: 0.227 (data_loss: 0.227, reg_loss: 0.000), lr: 0.00018446781036709093\n",
    "step: 300, acc: 0.898, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000), lr: 0.00018112660749864155\n",
    "step: 400, acc: 0.914, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000), lr: 0.00017790428749332856\n",
    "step: 468, acc: 0.917, loss: 0.192 (data_loss: 0.192, reg_loss: 0.000), lr: 0.00017577781683951485\n",
    "training, acc: 0.894, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.00017577781683951485\n",
    "validation, acc: 0.874, loss: 0.354\n",
    "validation, acc: 0.874, loss: 0.354\n",
    "\n",
    "Next, we can also run evaluation on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c975eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc412f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696907ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1e568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20379dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06a14f80",
   "metadata": {},
   "source": [
    "Running this prints:\n",
    ">>>\n",
    "validation, acc: 0.895, loss: 0.285\n",
    "\n",
    "\"Validation\" here means that we evaluated the model, but we have done this using the training data. We compare that to the result of training on this data which we have just performed:\n",
    "training, acc: 0.894, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000), lr: 0.00017577781683951485\n",
    "There is a discrepancy between accuracy and loss values because the model prints accuracy and loss accumulated during the epoch, while the model was still learning; meaning that mean accuracy and loss differ from the evaluation on the training data that has been run after the last epoch of training.\n",
    "\n",
    "**Running evaluation on the training data at the end of the training process will return the final accuracy and loss.**\n",
    "\n",
    "##### Next Step\n",
    "[[Saving and Loading Model and Their Parameters]]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
